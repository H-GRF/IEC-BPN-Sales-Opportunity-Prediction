{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8374604,"sourceType":"datasetVersion","datasetId":4979178}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ntrain_data =pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - train_bnp.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - test_bnp.csv\")\nsubm=pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - sample.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-11T10:25:11.987955Z","iopub.execute_input":"2024-05-11T10:25:11.988775Z","iopub.status.idle":"2024-05-11T10:25:14.012839Z","shell.execute_reply.started":"2024-05-11T10:25:11.988740Z","shell.execute_reply":"2024-05-11T10:25:14.011763Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Check for missing values in both training and test datasets\nmissing_train = train_data.isnull().sum()\nmissing_test = test_data.isnull().sum()\nmissing_train, missing_test","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:25:14.014975Z","iopub.execute_input":"2024-05-11T10:25:14.015356Z","iopub.status.idle":"2024-05-11T10:25:14.039373Z","shell.execute_reply.started":"2024-05-11T10:25:14.015322Z","shell.execute_reply":"2024-05-11T10:25:14.038438Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(id_client                                0\n Agence                                   0\n Code_catégorie_client                    0\n Age                                    219\n Genre                                    0\n Etat civil                               0\n Pays_naissance                         219\n code_pays_nationalite                    0\n Statut_de_résidence_fiscale              0\n Activité_Principale_Economique       70939\n Catégories_socio-professionnelle       200\n nom_employeur_1                      20241\n Secteur_Activité_Economique_Local    70939\n Démarches_Collectives                75219\n Notation                                81\n Segmentation_commerciale                 0\n ANCIENNETE                             149\n Avg_mt_mvt_cdt_reel                      0\n Avg_mt_mvt_cdt_ficitif                   0\n Avg_mt_mvt_dbt_reel                      0\n Avg_mt_mvt_dbt_fictif                    0\n Avg_solde_maximal_mensuel                0\n Avg_solde_minimal_mensuel                0\n Avg_solde_fin_mensuel                    0\n Avg_solde_moyen_mensuel                  0\n Median_mt_mvt_cdt_reel                   0\n Median_mt_mvt_cdt_ficitif                0\n Median_mt_mvt_dbt_reel                   0\n Median_mt_mvt_dbt_fictif                 0\n Median_solde_maximal_mensuel             0\n Median_solde_minimal_mensuel             0\n Median_solde_fin_mensuel                 0\n Median_solde_moyen_mensuel               0\n AVOIR_CHEQUIER                           0\n AVOIR_COMPTE_D_EPARGNE_A_VUE             0\n AVOIR_COMPTES_A_VUE                      0\n CARTE_VISA                               0\n DECES                                    0\n MRH                                      0\n PACK_BLEDI_ARE                           0\n TOUT_EN_UN                               0\n COMPTE_D_EPARGNE_ZERO                    0\n COMPTES_DEVISES                          0\n dtype: int64,\n id_client                                0\n Agence                                   0\n Code_catégorie_client                    0\n Age                                     53\n Genre                                    0\n Etat civil                               0\n Pays_naissance                          53\n code_pays_nationalite                    0\n Statut_de_résidence_fiscale              0\n Activité_Principale_Economique       21103\n Catégories_socio-professionnelle        49\n nom_employeur_1                       6090\n Secteur_Activité_Economique_Local    21103\n Démarches_Collectives                22459\n Notation                                28\n Segmentation_commerciale                 0\n ANCIENNETE                              50\n Avg_mt_mvt_cdt_reel                      0\n Avg_mt_mvt_cdt_ficitif                   0\n Avg_mt_mvt_dbt_reel                      0\n Avg_mt_mvt_dbt_fictif                    0\n Avg_solde_maximal_mensuel                0\n Avg_solde_minimal_mensuel                0\n Avg_solde_fin_mensuel                    0\n Avg_solde_moyen_mensuel                  0\n Median_mt_mvt_cdt_reel                   0\n Median_mt_mvt_cdt_ficitif                0\n Median_mt_mvt_dbt_reel                   0\n Median_mt_mvt_dbt_fictif                 0\n Median_solde_maximal_mensuel             0\n Median_solde_minimal_mensuel             0\n Median_solde_fin_mensuel                 0\n Median_solde_moyen_mensuel               0\n AVOIR_CHEQUIER                           0\n AVOIR_COMPTE_D_EPARGNE_A_VUE             0\n AVOIR_COMPTES_A_VUE                      0\n dtype: int64)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\ncategorical_cols = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\nnumeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\ntarget_cols = ['CARTE_VISA', 'DECES', 'MRH', 'PACK_BLEDI_ARE', 'TOUT_EN_UN', 'COMPTE_D_EPARGNE_ZERO', 'COMPTES_DEVISES']\nfor col in target_cols:\n    if col in numeric_cols:\n        numeric_cols.remove(col)\nnumeric_transformer = SimpleImputer(strategy='mean')\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\npreprocessor.fit(train_data)\nX_train = preprocessor.transform(train_data)\nX_test = preprocessor.transform(test_data)\ny_train = train_data[target_cols]\nX_train.shape, X_test.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:25:14.040666Z","iopub.execute_input":"2024-05-11T10:25:14.041009Z","iopub.status.idle":"2024-05-11T10:25:15.815335Z","shell.execute_reply.started":"2024-05-11T10:25:14.040982Z","shell.execute_reply":"2024-05-11T10:25:15.814381Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((76429, 202), (22830, 202), (76429, 7))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import f1_score\nforest = XGBClassifier(n_estimators=300, random_state=42, learning_rate = 0.03)\nmulti_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\nmulti_target_forest.fit(X_train, y_train)\ny_train_pred = multi_target_forest.predict(X_train)\ntrain_f1 = f1_score(y_train, y_train_pred, average='micro')\nprint(f\"Training F1 Micro Score: {train_f1}\")\ny_test_pred = multi_target_forest.predict(X_test)\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:26:47.560983Z","iopub.execute_input":"2024-05-11T10:26:47.561344Z","iopub.status.idle":"2024-05-11T10:27:13.277391Z","shell.execute_reply.started":"2024-05-11T10:26:47.561312Z","shell.execute_reply":"2024-05-11T10:27:13.276287Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training F1 Micro Score: 0.828942000538814\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score\nforest = XGBClassifier(n_estimators=300, random_state=42, trees= 1000, learning_rate = 0.03)\nmulti_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\nmulti_target_forest.fit(X_train, y_train)\ny_train_pred = multi_target_forest.predict(X_train)\ntrain_f1 = f1_score(y_train, y_train_pred, average='micro')\nprint(f\"Training F1 Micro Score: {train_f1}\")\ny_test_pred = multi_target_forest.predict(X_test)\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:32:32.420750Z","iopub.execute_input":"2024-05-11T10:32:32.421395Z","iopub.status.idle":"2024-05-11T10:32:56.442194Z","shell.execute_reply.started":"2024-05-11T10:32:32.421364Z","shell.execute_reply":"2024-05-11T10:32:56.441162Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:32] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:32] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:33] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:33] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:38] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:41] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [10:32:42] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Training F1 Micro Score: 0.828942000538814\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score\nforest = XGBClassifier(n_estimators=1000, random_state=42, trees= 100, learning_rate = 0.1)\nmulti_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\nmulti_target_forest.fit(X_train, y_train)\ny_train_pred = multi_target_forest.predict(X_train)\ntrain_f1 = f1_score(y_train, y_train_pred, average='micro')\nprint(f\"Training F1 Micro Score: {train_f1}\")\ny_test_pred = multi_target_forest.predict(X_test)\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:21:50.968099Z","iopub.execute_input":"2024-05-10T11:21:50.968959Z","iopub.status.idle":"2024-05-10T11:23:25.343730Z","shell.execute_reply.started":"2024-05-10T11:21:50.968913Z","shell.execute_reply":"2024-05-10T11:23:25.342215Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:21:51] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:21:51] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:21:51] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:21:51] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:22:12] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:22:25] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:22:25] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score\nforest = RandomForestClassifier(n_estimators=300, random_state=42)\nmulti_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\nmulti_target_forest.fit(X_train, y_train)\ny_train_pred = multi_target_forest.predict(X_train)\ntrain_f1 = f1_score(y_train, y_train_pred, average='micro')\nprint(f\"Training F1 Micro Score: {train_f1}\")\ny_test_pred = multi_target_forest.predict(X_test)\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:33:39.181830Z","iopub.execute_input":"2024-05-11T10:33:39.182192Z","iopub.status.idle":"2024-05-11T10:39:39.232195Z","shell.execute_reply.started":"2024-05-11T10:33:39.182161Z","shell.execute_reply":"2024-05-11T10:39:39.230898Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score\n\nxgb_model = xgb.XGBClassifier(n_estimators=300, learning_rate=0.2, random_state=42)\nparameters = {\n    'max_depth': [5, 7],\n    'learning_rate': [0.01, 0.1],\n    'subsample': [0.8, 1]\n}\nclf = GridSearchCV(xgb_model, parameters, scoring='f1_micro', cv=3)\nmulti_target_model = MultiFulltOutputClassifier(clf, n_jobs=-1)\nmulti_target_model.fit(X_train, y_train)\ny_train_pred = multi_target_model.predict(X_train)\ntrain_f1 = f1_score(y_train, y_train_pred, average='micro')\nprint(f\"Training F1 Micro Score: {train_f1}\")\ny_test_pred = multi_target_model.predict(X_test)\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:39:41.134314Z","iopub.execute_input":"2024-05-11T10:39:41.134719Z","iopub.status.idle":"2024-05-11T10:39:41.171899Z","shell.execute_reply.started":"2024-05-11T10:39:41.134688Z","shell.execute_reply":"2024-05-11T10:39:41.170463Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(xgb_model, parameters, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m multi_target_model \u001b[38;5;241m=\u001b[39m \u001b[43mMultiFulltOutputClassifier\u001b[49m(clf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m multi_target_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     17\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m multi_target_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n","\u001b[0;31mNameError\u001b[0m: name 'MultiFulltOutputClassifier' is not defined"],"ename":"NameError","evalue":"name 'MultiFulltOutputClassifier' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score\nfrom xgboost import XGBClassifier\n\ntrain_data =pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - train_bnp.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - test_bnp.csv\")\nsubm=pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - sample.csv\")\ntarget_cols = ['CARTE_VISA', 'DECES', 'MRH', 'PACK_BLEDI_ARE', 'TOUT_EN_UN', 'COMPTE_D_EPARGNE_ZERO', 'COMPTES_DEVISES']\nX_train = train_data.drop(columns=target_cols, errors='ignore')\ny_train = train_data[target_cols]\nnumeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', KNNImputer(n_neighbors=5)),  # Using KNN imputer for numeric columns\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', MultiOutputClassifier(XGBClassifier(n_estimators=100, random_state=42, trees = 1000, learning_rate = 0.1)))\n])\npipeline.fit(X_train, y_train)\ny_train_pred = pipeline.predict(X_train)\ntrain_f1 = f1_score(y_train, y_train_pred, average='micro')\nprint(f\"Training F1 Micro Score: {train_f1}\")\nif set(numeric_cols).union(categorical_cols).issubset(test_data.columns):\n    y_test_pred = pipeline.predict(test_data[numeric_cols + categorical_cols])\n    subm[target_cols] = y_test_pred\n    subm.to_csv('final_submission.csv', index=False)\nelse:\n    print(\"Test data is missing necessary columns.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T13:41:08.616543Z","iopub.execute_input":"2024-05-10T13:41:08.617158Z","iopub.status.idle":"2024-05-10T13:54:30.300588Z","shell.execute_reply.started":"2024-05-10T13:41:08.617127Z","shell.execute_reply":"2024-05-10T13:54:30.298806Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:47] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:49] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:50] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:51] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:52] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:53] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [13:49:54] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"trees\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 38\u001b[0m\n\u001b[1;32m     33\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     34\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     35\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, MultiOutputClassifier(XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, trees \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)))\n\u001b[1;32m     36\u001b[0m ])\n\u001b[1;32m     37\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 38\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m train_f1 \u001b[38;5;241m=\u001b[39m f1_score(y_train, y_train_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining F1 Micro Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    478\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 480\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:800\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 800\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    652\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    654\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    655\u001b[0m     )\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:876\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m--> 876\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:658\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    656\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[0;32m--> 658\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/impute/_knn.py:357\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# process in fixed-memory chunks\u001b[39;00m\n\u001b[1;32m    349\u001b[0m gen \u001b[38;5;241m=\u001b[39m pairwise_distances_chunked(\n\u001b[1;32m    350\u001b[0m     X[row_missing_idx, :],\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     reduce_func\u001b[38;5;241m=\u001b[39mprocess_chunk,\n\u001b[1;32m    356\u001b[0m )\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# process_chunk modifies X in place. No return value.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_empty_features:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1866\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[0;32m-> 1867\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1869\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1871\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   2037\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 2039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:474\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    471\u001b[0m X[missing_X] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    472\u001b[0m Y[missing_Y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 474\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Adjust distances for missing values\u001b[39;00m\n\u001b[1;32m    477\u001b[0m XX \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m X\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:328\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         )\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:369\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    371\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 192\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Example of creating aggregated features\nX_train['monthly_avg_credit'] = train_data.groupby('id_client')['amount_credit'].transform(lambda x: x.resample('M').mean())\nX_train['quarterly_var_balance'] = train_data.groupby('id_client')['balance'].transform(lambda x: x.resample('Q').var())\n# Example of creating demographic features\nX_train['age_group'] = pd.cut(X_train['age'], bins=[18, 35, 65, 100], labels=['young_adult', 'adult', 'senior'])\nX_train['is_family'] = X_train['marital_status'].apply(lambda x: 1 if x in ['Married', 'Divorced'] else 0)\n# Example of creating behavioral features\nX_train['utilization_rate'] = X_train.apply(lambda row: row['products_used'] / row['products_offered'], axis=1)\nX_train['days_since_last_transaction'] = (pd.to_datetime('today') - pd.to_datetime(X_train['last_transaction_date'])).dt.days\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()\nX_train['sentiment_score'] = train_data['customer_feedback'].apply(lambda x: sia.polarity_scores(x)['compound'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T13:54:30.301962Z","iopub.status.idle":"2024-05-10T13:54:30.302362Z","shell.execute_reply.started":"2024-05-10T13:54:30.302163Z","shell.execute_reply":"2024-05-10T13:54:30.302179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'classifier__estimator__max_depth': [3, 5, 7],\n    'classifier__estimator__min_child_weight': [1, 3],\n    'classifier__estimator__subsample': [0.6, 0.8],\n    'classifier__estimator__learning_rate': [0.1]\n}\ngrid_search = GridSearchCV(multi_target_forest, param_grid, cv=3, scoring='f1_micro', verbose=2)\ngrid_search.fit(X_train, y_train)\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))","metadata":{"execution":{"iopub.status.busy":"2024-05-10T13:54:42.595860Z","iopub.execute_input":"2024-05-10T13:54:42.596713Z","iopub.status.idle":"2024-05-10T13:54:43.023870Z","shell.execute_reply.started":"2024-05-10T13:54:42.596680Z","shell.execute_reply":"2024-05-10T13:54:43.022432Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 12 candidates, totalling 36 fits\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__estimator__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__estimator__min_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__estimator__subsample\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.8\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__estimator__learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m]\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(multi_target_forest, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest cross-validation score: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid_search\u001b[38;5;241m.\u001b[39mbest_score_))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:674\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    672\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 674\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcloned_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    678\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:205\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[1;32m    204\u001b[0m     local_valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[1;32m    211\u001b[0m     nested_params[key][sub_key] \u001b[38;5;241m=\u001b[39m value\n","\u001b[0;31mValueError\u001b[0m: Invalid parameter 'classifier' for estimator MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              learning_rate=0.1, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=100, n_jobs=None,\n                                              num_parallel_tree=None,\n                                              random_state=42, ...),\n                      n_jobs=-1). Valid parameters are: ['estimator', 'n_jobs']."],"ename":"ValueError","evalue":"Invalid parameter 'classifier' for estimator MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              learning_rate=0.1, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=100, n_jobs=None,\n                                              num_parallel_tree=None,\n                                              random_state=42, ...),\n                      n_jobs=-1). Valid parameters are: ['estimator', 'n_jobs'].","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom xgboost import XGBClassifier\ntrain_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - train_bnp.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - test_bnp.csv\")\nsubm = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - sample.csv\")\ncategorical_cols = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\nnumeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\ntarget_cols = ['CARTE_VISA', 'DECES', 'MRH', 'PACK_BLEDI_ARE', 'TOUT_EN_UN', 'COMPTE_D_EPARGNE_ZERO', 'COMPTES_DEVISES']\nnumeric_cols = [col for col in numeric_cols if col not in target_cols]\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', SimpleImputer(strategy='mean'), numeric_cols),\n        ('cat', Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n        ]), categorical_cols)\n    ])\nmodel = MultiOutputClassifier(XGBClassifier(n_estimators=300, random_state=42))\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\nparam_grid = {\n    'model__estimator__max_depth': [7,10],\n    'model__estimator__learning_rate': [0.2,0.3]\n}\nscorer = make_scorer(f1_score, average='micro')\ngrid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=scorer, verbose=2)\ngrid_search.fit(train_data.drop(columns=target_cols), train_data[target_cols])\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\ny_test_pred = grid_search.predict(test_data[numeric_cols + categorical_cols])\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom xgboost import XGBClassifier\ntrain_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - train_bnp.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - test_bnp.csv\")\nsubm = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - sample.csv\")\ncategorical_cols = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\nnumeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\ntarget_cols = ['CARTE_VISA', 'DECES', 'MRH', 'PACK_BLEDI_ARE', 'TOUT_EN_UN', 'COMPTE_D_EPARGNE_ZERO', 'COMPTES_DEVISES']\nnumeric_cols = [col for col in numeric_cols if col not in target_cols]\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', SimpleImputer(strategy='mean'), numeric_cols),\n        ('cat', Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n        ]), categorical_cols)\n    ])\nmodel = MultiOutputClassifier(XGBClassifier(n_estimators=100, random_state=42))\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\nparam_grid = {\n    'model__estimator__max_depth': [7,10],\n    'model__estimator__learning_rate': [0.2,0.3]\n}\nscorer = make_scorer(f1_score, average='micro')\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scorer, verbose=2)\ngrid_search.fit(train_data.drop(columns=target_cols), train_data[target_cols])\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\ny_test_pred = grid_search.predict(test_data[numeric_cols + categorical_cols])\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:58:25.001684Z","iopub.execute_input":"2024-05-11T10:58:25.002491Z","iopub.status.idle":"2024-05-11T11:02:24.103643Z","shell.execute_reply.started":"2024-05-11T10:58:25.002459Z","shell.execute_reply":"2024-05-11T11:02:24.102865Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   8.1s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   9.2s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   7.9s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   8.1s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   8.0s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=10; total time=  15.3s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=10; total time=  14.3s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=10; total time=  15.1s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=10; total time=  14.4s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=10; total time=  15.5s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=7; total time=   7.9s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=7; total time=   7.9s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=7; total time=   9.0s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=7; total time=   8.0s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=7; total time=   8.1s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=10; total time=  14.3s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=10; total time=  13.8s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=10; total time=  13.8s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=10; total time=  14.7s\n[CV] END model__estimator__learning_rate=0.3, model__estimator__max_depth=10; total time=  14.4s\nBest parameters: {'model__estimator__learning_rate': 0.2, 'model__estimator__max_depth': 7}\nBest cross-validation score: 0.817\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom xgboost import XGBClassifier\ntrain_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - train_bnp.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - test_bnp.csv\")\nsubm = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - sample.csv\")\ncategorical_cols = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\nnumeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\ntarget_cols = ['CARTE_VISA', 'DECES', 'MRH', 'PACK_BLEDI_ARE', 'TOUT_EN_UN', 'COMPTE_D_EPARGNE_ZERO', 'COMPTES_DEVISES']\nnumeric_cols = [col for col in numeric_cols if col not in target_cols]\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', SimpleImputer(strategy='mean'), numeric_cols),\n        ('cat', Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n        ]), categorical_cols)\n    ])\nmodel = MultiOutputClassifier(XGBClassifier(n_estimators=100, random_state=42))\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\nparam_grid = {\n    'model__estimator__max_depth': [7,5],\n    'model__estimator__learning_rate': [0.2,0.1]\n}\nscorer = make_scorer(f1_score, average='micro')\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scorer, verbose=2)\ngrid_search.fit(train_data.drop(columns=target_cols), train_data[target_cols])\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\ny_test_pred = grid_search.predict(test_data[numeric_cols + categorical_cols])\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T11:03:03.681104Z","iopub.execute_input":"2024-05-11T11:03:03.681466Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   8.0s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   7.9s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   8.9s\n[CV] END model__estimator__learning_rate=0.2, model__estimator__max_depth=7; total time=   8.0s\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom xgboost import XGBClassifier\ntrain_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - train_bnp.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - test_bnp.csv\")\nsubm = pd.read_csv(\"/kaggle/input/dataset/BNP KAGGLE - sample.csv\")\ncategorical_cols = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\nnumeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\ntarget_cols = ['CARTE_VISA', 'DECES', 'MRH', 'PACK_BLEDI_ARE', 'TOUT_EN_UN', 'COMPTE_D_EPARGNE_ZERO', 'COMPTES_DEVISES']\nnumeric_cols = [col for col in numeric_cols if col not in target_cols]\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', SimpleImputer(strategy='mean'), numeric_cols),\n        ('cat', Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n        ]), categorical_cols)\n    ])\nmodel = MultiOutputClassifier(XGBClassifier(n_estimators=300, random_state=42))\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\nparam_grid = {\n    'model__estimator__max_depth': [7,5],\n    'model__estimator__learning_rate': [0.05,0.1]\n}\nscorer = make_scorer(f1_score, average='micro')\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scorer, verbose=2)\ngrid_search.fit(train_data.drop(columns=target_cols), train_data[target_cols])\nprint(\"Best parameters:\", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\ny_test_pred = grid_search.predict(test_data[numeric_cols + categorical_cols])\nsubm[target_cols] = y_test_pred\nsubm.to_csv('final_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T11:14:06.742326Z","iopub.execute_input":"2024-05-11T11:14:06.743132Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n[CV] END model__estimator__learning_rate=0.05, model__estimator__max_depth=7; total time=  22.6s\n[CV] END model__estimator__learning_rate=0.05, model__estimator__max_depth=7; total time=  31.9s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}